{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Виконання"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Завдання перше"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зчитаємо файл. with - оператор контексту, який автоматично закриває файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At three  o'clock 12/05/1895 precisely I was at Baker Street, but Holmes had not\n",
      "yet returned (005)-456-34-23. The landlady informed me that he baker_street@here.uk had left the house\n",
      "shortly after eight o'clock in the morning. I sat down beside the\n",
      "fire, however, with the intention of awaiting him,, however long he\n",
      "might be. 145 124 245 I was already 67-56-34 deeply interested in his inquiry, for, though\n",
      "it was surrounded by none of the grim and strange features which\n",
      "were Watson3@gmail.com associated with the two crimes which I have already recorded,\n",
      "still, the nature of  the case and the exalted station of his client\n",
      "gave it a character of its own 1896/01/23.. Indeed, apart from the nature of the\n",
      "investigation which my friend had on hand, there was something in his\n",
      "masterly 5618 4582 8225 1471 grasp of a situation, and his (03)-8-45-34 keen, incisive reasoning, which\n",
      "made it a pleasure to me to study his system of work, and to follow the\n",
      "quick, subtle 4987 1514 6555 4212 methods by which he disentangled the most inextricable\n",
      "mysteries. So accustomed was I ShHolmes@mail.uk to his invariable success that the very\n",
      "possibility of his failing  had ceased to enter into my head.\n"
     ]
    }
   ],
   "source": [
    "with open('text1.txt', 'r') as file:\n",
    "    s = ''.join(file.readlines())\n",
    "print(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Зчитування файлу*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Імпортуємо SpaCy та словник англійської мови."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "py_nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Імпортування SpaCy*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Покажемо розбиття тексту на токени. Бачимо, що токени з текстами складно піддати обробці за допомогою звичайних атрибутів Matcher паттерна, тому використаємо атрибут REGEX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At',\n",
       " 'three',\n",
       " ' ',\n",
       " \"o'clock\",\n",
       " '12/05/1895',\n",
       " 'precisely',\n",
       " 'I',\n",
       " 'was',\n",
       " 'at',\n",
       " 'Baker',\n",
       " 'Street',\n",
       " ',',\n",
       " 'but',\n",
       " 'Holmes',\n",
       " 'had',\n",
       " 'not',\n",
       " '\\n',\n",
       " 'yet',\n",
       " 'returned',\n",
       " '(',\n",
       " '005)-456',\n",
       " '-',\n",
       " '34',\n",
       " '-',\n",
       " '23',\n",
       " '.',\n",
       " 'The',\n",
       " 'landlady',\n",
       " 'informed',\n",
       " 'me',\n",
       " 'that',\n",
       " 'he',\n",
       " 'baker_street@here.uk',\n",
       " 'had',\n",
       " 'left',\n",
       " 'the',\n",
       " 'house',\n",
       " '\\n',\n",
       " 'shortly',\n",
       " 'after',\n",
       " 'eight',\n",
       " \"o'clock\",\n",
       " 'in',\n",
       " 'the',\n",
       " 'morning',\n",
       " '.',\n",
       " 'I',\n",
       " 'sat',\n",
       " 'down',\n",
       " 'beside',\n",
       " 'the',\n",
       " '\\n',\n",
       " 'fire',\n",
       " ',',\n",
       " 'however',\n",
       " ',',\n",
       " 'with',\n",
       " 'the',\n",
       " 'intention',\n",
       " 'of',\n",
       " 'awaiting',\n",
       " 'him',\n",
       " ',',\n",
       " ',',\n",
       " 'however',\n",
       " 'long',\n",
       " 'he',\n",
       " '\\n',\n",
       " 'might',\n",
       " 'be',\n",
       " '.',\n",
       " '145',\n",
       " '124',\n",
       " '245',\n",
       " 'I',\n",
       " 'was',\n",
       " 'already',\n",
       " '67',\n",
       " '-',\n",
       " '56',\n",
       " '-',\n",
       " '34',\n",
       " 'deeply',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'his',\n",
       " 'inquiry',\n",
       " ',',\n",
       " 'for',\n",
       " ',',\n",
       " 'though',\n",
       " '\\n',\n",
       " 'it',\n",
       " 'was',\n",
       " 'surrounded',\n",
       " 'by',\n",
       " 'none',\n",
       " 'of',\n",
       " 'the',\n",
       " 'grim',\n",
       " 'and',\n",
       " 'strange',\n",
       " 'features',\n",
       " 'which',\n",
       " '\\n',\n",
       " 'were',\n",
       " 'Watson3@gmail.com',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'the',\n",
       " 'two',\n",
       " 'crimes',\n",
       " 'which',\n",
       " 'I',\n",
       " 'have',\n",
       " 'already',\n",
       " 'recorded',\n",
       " ',',\n",
       " '\\n',\n",
       " 'still',\n",
       " ',',\n",
       " 'the',\n",
       " 'nature',\n",
       " 'of',\n",
       " ' ',\n",
       " 'the',\n",
       " 'case',\n",
       " 'and',\n",
       " 'the',\n",
       " 'exalted',\n",
       " 'station',\n",
       " 'of',\n",
       " 'his',\n",
       " 'client',\n",
       " '\\n',\n",
       " 'gave',\n",
       " 'it',\n",
       " 'a',\n",
       " 'character',\n",
       " 'of',\n",
       " 'its',\n",
       " 'own',\n",
       " '1896/01/23',\n",
       " '..',\n",
       " 'Indeed',\n",
       " ',',\n",
       " 'apart',\n",
       " 'from',\n",
       " 'the',\n",
       " 'nature',\n",
       " 'of',\n",
       " 'the',\n",
       " '\\n',\n",
       " 'investigation',\n",
       " 'which',\n",
       " 'my',\n",
       " 'friend',\n",
       " 'had',\n",
       " 'on',\n",
       " 'hand',\n",
       " ',',\n",
       " 'there',\n",
       " 'was',\n",
       " 'something',\n",
       " 'in',\n",
       " 'his',\n",
       " '\\n',\n",
       " 'masterly',\n",
       " '5618',\n",
       " '4582',\n",
       " '8225',\n",
       " '1471',\n",
       " 'grasp',\n",
       " 'of',\n",
       " 'a',\n",
       " 'situation',\n",
       " ',',\n",
       " 'and',\n",
       " 'his',\n",
       " '(',\n",
       " '03)-8',\n",
       " '-',\n",
       " '45',\n",
       " '-',\n",
       " '34',\n",
       " 'keen',\n",
       " ',',\n",
       " 'incisive',\n",
       " 'reasoning',\n",
       " ',',\n",
       " 'which',\n",
       " '\\n',\n",
       " 'made',\n",
       " 'it',\n",
       " 'a',\n",
       " 'pleasure',\n",
       " 'to',\n",
       " 'me',\n",
       " 'to',\n",
       " 'study',\n",
       " 'his',\n",
       " 'system',\n",
       " 'of',\n",
       " 'work',\n",
       " ',',\n",
       " 'and',\n",
       " 'to',\n",
       " 'follow',\n",
       " 'the',\n",
       " '\\n',\n",
       " 'quick',\n",
       " ',',\n",
       " 'subtle',\n",
       " '4987',\n",
       " '1514',\n",
       " '6555',\n",
       " '4212',\n",
       " 'methods',\n",
       " 'by',\n",
       " 'which',\n",
       " 'he',\n",
       " 'disentangled',\n",
       " 'the',\n",
       " 'most',\n",
       " 'inextricable',\n",
       " '\\n',\n",
       " 'mysteries',\n",
       " '.',\n",
       " 'So',\n",
       " 'accustomed',\n",
       " 'was',\n",
       " 'I',\n",
       " 'ShHolmes@mail.uk',\n",
       " 'to',\n",
       " 'his',\n",
       " 'invariable',\n",
       " 'success',\n",
       " 'that',\n",
       " 'the',\n",
       " 'very',\n",
       " '\\n',\n",
       " 'possibility',\n",
       " 'of',\n",
       " 'his',\n",
       " 'failing',\n",
       " ' ',\n",
       " 'had',\n",
       " 'ceased',\n",
       " 'to',\n",
       " 'enter',\n",
       " 'into',\n",
       " 'my',\n",
       " 'head',\n",
       " '.']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = py_nlp(s)\n",
    "[tok.text for tok in doc]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Токени*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визанчимо паттерн та знайдемо всі номери телефонів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3884770101205390969, 19, 25) (005)-456-34-23\n",
      "(3884770101205390969, 71, 74) 145 124 245\n",
      "(3884770101205390969, 77, 82) 67-56-34\n",
      "(3884770101205390969, 179, 185) (03)-8-45-34\n"
     ]
    }
   ],
   "source": [
    "patterns = [\n",
    "    [{\"IS_DIGIT\": True, 'LENGTH': 3, 'OP': '{3,}'}],\n",
    "    [{\"IS_DIGIT\": True, 'LENGTH': 2},\n",
    "     {'TEXT': '-'},\n",
    "     {\"IS_DIGIT\": True, 'LENGTH': 2},\n",
    "     {'TEXT': '-'},\n",
    "     {\"IS_DIGIT\": True, 'LENGTH': 2}],\n",
    "    [{'TEXT': '('},\n",
    "     {'TEXT': {'REGEX': r'\\d\\d\\d[)][-]\\d\\d\\d'}},\n",
    "     {'TEXT': '-'},\n",
    "     {\"IS_DIGIT\": True, 'LENGTH': 2},\n",
    "     {'TEXT': '-'},\n",
    "     {\"IS_DIGIT\": True, 'LENGTH': 2}],\n",
    "    [{'TEXT': '('},\n",
    "     {'TEXT': {'REGEX': r'\\d\\d[)][-]\\d'}},\n",
    "     {'TEXT': '-'},\n",
    "     {\"IS_DIGIT\": True, 'LENGTH': 2},\n",
    "     {'TEXT': '-'},\n",
    "     {\"IS_DIGIT\": True, 'LENGTH': 2}]\n",
    "]\n",
    "matcher = Matcher(py_nlp.vocab)\n",
    "matcher.add(\"PROPER_PHONE_NUMBER\", patterns)\n",
    "matches = matcher(doc)\n",
    "for match in matches:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Знаходження номерів телефонів*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Замінимо цифри на зірочки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At three  o'clock 12/05/1895 precisely I was at Baker Street, but Holmes had not\n",
      "yet returned (0**)-***-**-**. The landlady informed me that he baker_street@here.uk had left the house\n",
      "shortly after eight o'clock in the morning. I sat down beside the\n",
      "fire, however, with the intention of awaiting him,, however long he\n",
      "might be. 1******** I was already 6*-**-** deeply interested in his inquiry, for, though\n",
      "it was surrounded by none of the grim and strange features which\n",
      "were Watson3@gmail.com associated with the two crimes which I have already recorded,\n",
      "still, the nature of  the case and the exalted station of his client\n",
      "gave it a character of its own 1896/01/23.. Indeed, apart from the nature of the\n",
      "investigation which my friend had on hand, there was something in his\n",
      "masterly 5618 4582 8225 1471 grasp of a situation, and his (0*)-*-**-** keen, incisive reasoning, which\n",
      "made it a pleasure to me to study his system of work, and to follow the\n",
      "quick, subtle 4987 1514 6555 4212 methods by which he disentangled the most inextricable\n",
      "mysteries. So accustomed was I ShHolmes@mail.uk to his invariable success that the very\n",
      "possibility of his failing  had ceased to enter into my head.\n"
     ]
    }
   ],
   "source": [
    "tokens = [el.text for el in doc]\n",
    "for match in matches:\n",
    "    found_first_digit = False\n",
    "    elememts = []\n",
    "    tt = doc[match[1]:match[2]]\n",
    "    for i, el in enumerate(tt):\n",
    "        chars = list(el.text)\n",
    "        for j, c in enumerate(chars):\n",
    "            if c.isdigit() and not found_first_digit:\n",
    "                found_first_digit = True\n",
    "                continue\n",
    "            elif c.isdigit() and found_first_digit:\n",
    "                chars[j] = '*'\n",
    "        elememts.append(''.join(chars))\n",
    "    s = s.replace(tt.text, f''.join(elememts))\n",
    "print(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Заміна тексту*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Завдання друге"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зчитаємо файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'US retail sales fell 0.3% in January, the biggest monthly decline since last August, driven down by a heavy fall in car sales.  The 3.3% fall in car sales had been expected, coming after December\\'s 4% rise in car sales, fuelled by generous pre-Christmas special offers. Excluding the car sector, US retail sales were up 0.6% in January, twice what some analysts had been expecting. US retail spending is expected to rise in 2005, but not as quickly as in 2004.  Steve Gallagher, US chief economist at SG Corporate & Investment Banking, said January\\'s figures were \"decent numbers\".  \"We are not seeing the numbers that we saw in the second half of 2004, but they are still pretty healthy,\" he added. Sales at appliance and electronic stores were down 0.6% in January, while sales at hardware stores dropped by 0.3% and furniture store sales dipped 0.1%. Sales at clothing and clothing accessory stores jumped 1.8%, while sales at general merchandise stores, a category that includes department stores, rose by 0.9%. These strong gains were in part put down to consumers spending gift vouchers they had been given for Christmas.  Sales at restaurants, bars and coffee houses rose by 0.3%, while grocery store sales were up 0.5%. In December, overall retail sales rose by 1.1%. Excluding the car sector, sales rose by just 0.3%. Parul Jain, deputy chief economist at Nomura Securities International, said consumer spending would continue to rise in 2005, only at a slower rate of growth than in 2004. \"Consumers continue to retain their strength in the first quarter,\" he said. Van Rourke, a bond strategist at Popular Securities, agreed that the latest retail sales figures were \"slightly stronger than expected\". '"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('lab7-1.txt', 'r') as file:\n",
    "    s = ''.join(file.readlines())\n",
    "doc = py_nlp(s)\n",
    "print(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Зчитування файлів*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Знайдемо та виведемо стоп-слова, які присутні у тексті."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['US',\n",
       " 'in',\n",
       " 'the',\n",
       " 'since',\n",
       " 'last',\n",
       " 'down',\n",
       " 'by',\n",
       " 'a',\n",
       " 'in',\n",
       " 'The',\n",
       " 'in',\n",
       " 'had',\n",
       " 'been',\n",
       " 'after',\n",
       " \"'s\",\n",
       " 'in',\n",
       " 'by',\n",
       " 'the',\n",
       " 'US',\n",
       " 'were',\n",
       " 'up',\n",
       " 'in',\n",
       " 'what',\n",
       " 'some',\n",
       " 'had',\n",
       " 'been',\n",
       " 'US',\n",
       " 'is',\n",
       " 'to',\n",
       " 'in',\n",
       " 'but',\n",
       " 'not',\n",
       " 'as',\n",
       " 'as',\n",
       " 'in',\n",
       " 'US',\n",
       " 'at',\n",
       " \"'s\",\n",
       " 'were',\n",
       " 'We',\n",
       " 'are',\n",
       " 'not',\n",
       " 'the',\n",
       " 'that',\n",
       " 'we',\n",
       " 'in',\n",
       " 'the',\n",
       " 'of',\n",
       " 'but',\n",
       " 'they',\n",
       " 'are',\n",
       " 'still',\n",
       " 'he',\n",
       " 'at',\n",
       " 'and',\n",
       " 'were',\n",
       " 'down',\n",
       " 'in',\n",
       " 'while',\n",
       " 'at',\n",
       " 'by',\n",
       " 'and',\n",
       " 'at',\n",
       " 'and',\n",
       " 'while',\n",
       " 'at',\n",
       " 'a',\n",
       " 'that',\n",
       " 'by',\n",
       " 'These',\n",
       " 'were',\n",
       " 'in',\n",
       " 'part',\n",
       " 'put',\n",
       " 'down',\n",
       " 'to',\n",
       " 'they',\n",
       " 'had',\n",
       " 'been',\n",
       " 'for',\n",
       " 'at',\n",
       " 'and',\n",
       " 'by',\n",
       " 'while',\n",
       " 'were',\n",
       " 'up',\n",
       " 'In',\n",
       " 'by',\n",
       " 'the',\n",
       " 'by',\n",
       " 'just',\n",
       " 'at',\n",
       " 'would',\n",
       " 'to',\n",
       " 'in',\n",
       " 'only',\n",
       " 'at',\n",
       " 'a',\n",
       " 'of',\n",
       " 'than',\n",
       " 'in',\n",
       " 'to',\n",
       " 'their',\n",
       " 'in',\n",
       " 'the',\n",
       " 'first',\n",
       " 'he',\n",
       " 'a',\n",
       " 'at',\n",
       " 'that',\n",
       " 'the',\n",
       " 'were',\n",
       " 'than']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = [token.text for token in doc if token.is_stop]\n",
    "stop_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Стоп-слова*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Знайдемо та виведемо всі іменники з тексту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[sales,\n",
       " decline,\n",
       " fall,\n",
       " car,\n",
       " sales,\n",
       " fall,\n",
       " car,\n",
       " sales,\n",
       " rise,\n",
       " car,\n",
       " sales,\n",
       " offers,\n",
       " car,\n",
       " sector,\n",
       " sales,\n",
       " analysts,\n",
       " spending,\n",
       " economist,\n",
       " figures,\n",
       " numbers,\n",
       " numbers,\n",
       " half,\n",
       " Sales,\n",
       " appliance,\n",
       " stores,\n",
       " sales,\n",
       " hardware,\n",
       " stores,\n",
       " furniture,\n",
       " store,\n",
       " sales,\n",
       " Sales,\n",
       " clothing,\n",
       " clothing,\n",
       " accessory,\n",
       " stores,\n",
       " sales,\n",
       " merchandise,\n",
       " stores,\n",
       " category,\n",
       " department,\n",
       " stores,\n",
       " gains,\n",
       " part,\n",
       " consumers,\n",
       " gift,\n",
       " vouchers,\n",
       " Sales,\n",
       " restaurants,\n",
       " bars,\n",
       " coffee,\n",
       " houses,\n",
       " grocery,\n",
       " store,\n",
       " sales,\n",
       " sales,\n",
       " car,\n",
       " sector,\n",
       " sales,\n",
       " economist,\n",
       " consumer,\n",
       " spending,\n",
       " rate,\n",
       " growth,\n",
       " Consumers,\n",
       " strength,\n",
       " quarter,\n",
       " bond,\n",
       " strategist,\n",
       " sales,\n",
       " figures]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = [token for token in doc if token.pos_ == 'NOUN' and token.text.isalpha()]\n",
    "nouns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Іменники*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Виведемо числа та дати."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3884770101205390969, 4, 5) 0.3\n",
      "(3884770101205390969, 29, 30) 3.3\n",
      "(3884770101205390969, 43, 44) 4\n",
      "(3884770101205390969, 69, 70) 0.6\n",
      "(3884770101205390969, 90, 91) 2005\n",
      "(3884770101205390969, 98, 99) 2004\n",
      "(3884770101205390969, 137, 138) second\n",
      "(3884770101205390969, 140, 141) 2004\n",
      "(3884770101205390969, 161, 162) 0.6\n",
      "(3884770101205390969, 173, 174) 0.3\n",
      "(3884770101205390969, 180, 181) 0.1\n",
      "(3884770101205390969, 191, 192) 1.8\n",
      "(3884770101205390969, 210, 211) 0.9\n",
      "(3884770101205390969, 244, 245) 0.3\n",
      "(3884770101205390969, 253, 254) 0.5\n",
      "(3884770101205390969, 264, 265) 1.1\n",
      "(3884770101205390969, 276, 277) 0.3\n",
      "(3884770101205390969, 298, 299) 2005\n",
      "(3884770101205390969, 309, 310) 2004\n",
      "(3884770101205390969, 320, 321) first\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(py_nlp.vocab)\n",
    "patterns = [[{'LIKE_NUM': True}]]\n",
    "matcher.add(\"PROPER_PHONE_NUMBER\", patterns)\n",
    "matches = matcher(doc)\n",
    "for match in matches:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Числа та дати*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
