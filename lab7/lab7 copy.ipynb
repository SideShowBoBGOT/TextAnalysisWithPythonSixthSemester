{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Виконання"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Завдання перше"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зчитаємо файл. with - оператор контексту, який автоматично закриває файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At three  o'clock 12/05/1895 precisely I was at Baker Street, but Holmes had not\n",
      "yet returned (005)-456-34-23. The landlady informed me that he baker_street@here.uk had left the house\n",
      "shortly after eight o'clock in the morning. I sat down beside the\n",
      "fire, however, with the intention of awaiting him,, however long he\n",
      "might be. 145 124 245 I was already 67-56-34 deeply interested in his inquiry, for, though\n",
      "it was surrounded by none of the grim and strange features which\n",
      "were Watson3@gmail.com associated with the two crimes which I have already recorded,\n",
      "still, the nature of  the case and the exalted station of his client\n",
      "gave it a character of its own 1896/01/23.. Indeed, apart from the nature of the\n",
      "investigation which my friend had on hand, there was something in his\n",
      "masterly 5618 4582 8225 1471 grasp of a situation, and his (03)-8-45-34 keen, incisive reasoning, which\n",
      "made it a pleasure to me to study his system of work, and to follow the\n",
      "quick, subtle 4987 1514 6555 4212 methods by which he disentangled the most inextricable\n",
      "mysteries. So accustomed was I ShHolmes@mail.uk to his invariable success that the very\n",
      "possibility of his failing  had ceased to enter into my head.\n"
     ]
    }
   ],
   "source": [
    "with open('text1.txt', 'r') as file:\n",
    "    s = ''.join(file.readlines())\n",
    "print(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Зчитування файлу*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Імпортуємо SpaCy та словник англійської мови."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "py_nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Імпортування SpaCy*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Покажемо розбиття тексту на токени. Бачимо, що токени з текстами складно піддати обробці за допомогою звичайних атрибутів Matcher паттерна, тому використаємо атрибут REGEX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At',\n",
       " 'three',\n",
       " ' ',\n",
       " \"o'clock\",\n",
       " '12/05/1895',\n",
       " 'precisely',\n",
       " 'I',\n",
       " 'was',\n",
       " 'at',\n",
       " 'Baker',\n",
       " 'Street',\n",
       " ',',\n",
       " 'but',\n",
       " 'Holmes',\n",
       " 'had',\n",
       " 'not',\n",
       " '\\n',\n",
       " 'yet',\n",
       " 'returned',\n",
       " '(',\n",
       " '005)-456',\n",
       " '-',\n",
       " '34',\n",
       " '-',\n",
       " '23',\n",
       " '.',\n",
       " 'The',\n",
       " 'landlady',\n",
       " 'informed',\n",
       " 'me',\n",
       " 'that',\n",
       " 'he',\n",
       " 'baker_street@here.uk',\n",
       " 'had',\n",
       " 'left',\n",
       " 'the',\n",
       " 'house',\n",
       " '\\n',\n",
       " 'shortly',\n",
       " 'after',\n",
       " 'eight',\n",
       " \"o'clock\",\n",
       " 'in',\n",
       " 'the',\n",
       " 'morning',\n",
       " '.',\n",
       " 'I',\n",
       " 'sat',\n",
       " 'down',\n",
       " 'beside',\n",
       " 'the',\n",
       " '\\n',\n",
       " 'fire',\n",
       " ',',\n",
       " 'however',\n",
       " ',',\n",
       " 'with',\n",
       " 'the',\n",
       " 'intention',\n",
       " 'of',\n",
       " 'awaiting',\n",
       " 'him',\n",
       " ',',\n",
       " ',',\n",
       " 'however',\n",
       " 'long',\n",
       " 'he',\n",
       " '\\n',\n",
       " 'might',\n",
       " 'be',\n",
       " '.',\n",
       " '145',\n",
       " '124',\n",
       " '245',\n",
       " 'I',\n",
       " 'was',\n",
       " 'already',\n",
       " '67',\n",
       " '-',\n",
       " '56',\n",
       " '-',\n",
       " '34',\n",
       " 'deeply',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'his',\n",
       " 'inquiry',\n",
       " ',',\n",
       " 'for',\n",
       " ',',\n",
       " 'though',\n",
       " '\\n',\n",
       " 'it',\n",
       " 'was',\n",
       " 'surrounded',\n",
       " 'by',\n",
       " 'none',\n",
       " 'of',\n",
       " 'the',\n",
       " 'grim',\n",
       " 'and',\n",
       " 'strange',\n",
       " 'features',\n",
       " 'which',\n",
       " '\\n',\n",
       " 'were',\n",
       " 'Watson3@gmail.com',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'the',\n",
       " 'two',\n",
       " 'crimes',\n",
       " 'which',\n",
       " 'I',\n",
       " 'have',\n",
       " 'already',\n",
       " 'recorded',\n",
       " ',',\n",
       " '\\n',\n",
       " 'still',\n",
       " ',',\n",
       " 'the',\n",
       " 'nature',\n",
       " 'of',\n",
       " ' ',\n",
       " 'the',\n",
       " 'case',\n",
       " 'and',\n",
       " 'the',\n",
       " 'exalted',\n",
       " 'station',\n",
       " 'of',\n",
       " 'his',\n",
       " 'client',\n",
       " '\\n',\n",
       " 'gave',\n",
       " 'it',\n",
       " 'a',\n",
       " 'character',\n",
       " 'of',\n",
       " 'its',\n",
       " 'own',\n",
       " '1896/01/23',\n",
       " '..',\n",
       " 'Indeed',\n",
       " ',',\n",
       " 'apart',\n",
       " 'from',\n",
       " 'the',\n",
       " 'nature',\n",
       " 'of',\n",
       " 'the',\n",
       " '\\n',\n",
       " 'investigation',\n",
       " 'which',\n",
       " 'my',\n",
       " 'friend',\n",
       " 'had',\n",
       " 'on',\n",
       " 'hand',\n",
       " ',',\n",
       " 'there',\n",
       " 'was',\n",
       " 'something',\n",
       " 'in',\n",
       " 'his',\n",
       " '\\n',\n",
       " 'masterly',\n",
       " '5618',\n",
       " '4582',\n",
       " '8225',\n",
       " '1471',\n",
       " 'grasp',\n",
       " 'of',\n",
       " 'a',\n",
       " 'situation',\n",
       " ',',\n",
       " 'and',\n",
       " 'his',\n",
       " '(',\n",
       " '03)-8',\n",
       " '-',\n",
       " '45',\n",
       " '-',\n",
       " '34',\n",
       " 'keen',\n",
       " ',',\n",
       " 'incisive',\n",
       " 'reasoning',\n",
       " ',',\n",
       " 'which',\n",
       " '\\n',\n",
       " 'made',\n",
       " 'it',\n",
       " 'a',\n",
       " 'pleasure',\n",
       " 'to',\n",
       " 'me',\n",
       " 'to',\n",
       " 'study',\n",
       " 'his',\n",
       " 'system',\n",
       " 'of',\n",
       " 'work',\n",
       " ',',\n",
       " 'and',\n",
       " 'to',\n",
       " 'follow',\n",
       " 'the',\n",
       " '\\n',\n",
       " 'quick',\n",
       " ',',\n",
       " 'subtle',\n",
       " '4987',\n",
       " '1514',\n",
       " '6555',\n",
       " '4212',\n",
       " 'methods',\n",
       " 'by',\n",
       " 'which',\n",
       " 'he',\n",
       " 'disentangled',\n",
       " 'the',\n",
       " 'most',\n",
       " 'inextricable',\n",
       " '\\n',\n",
       " 'mysteries',\n",
       " '.',\n",
       " 'So',\n",
       " 'accustomed',\n",
       " 'was',\n",
       " 'I',\n",
       " 'ShHolmes@mail.uk',\n",
       " 'to',\n",
       " 'his',\n",
       " 'invariable',\n",
       " 'success',\n",
       " 'that',\n",
       " 'the',\n",
       " 'very',\n",
       " '\\n',\n",
       " 'possibility',\n",
       " 'of',\n",
       " 'his',\n",
       " 'failing',\n",
       " ' ',\n",
       " 'had',\n",
       " 'ceased',\n",
       " 'to',\n",
       " 'enter',\n",
       " 'into',\n",
       " 'my',\n",
       " 'head',\n",
       " '.']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = py_nlp(s)\n",
    "[tok.text for tok in doc]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Токени*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визанчимо паттерн та знайдемо всі номери телефонів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3884770101205390969, 19, 25) (005)-456-34-23\n",
      "(3884770101205390969, 71, 74) 145 124 245\n",
      "(3884770101205390969, 77, 82) 67-56-34\n",
      "(3884770101205390969, 179, 185) (03)-8-45-34\n"
     ]
    }
   ],
   "source": [
    "patterns = [\n",
    "    [{\"IS_DIGIT\": True, 'LENGTH': 3, 'OP': '{3,}'}],\n",
    "    [{\"IS_DIGIT\": True, 'LENGTH': 2},\n",
    "     {'TEXT': '-'},\n",
    "     {\"IS_DIGIT\": True, 'LENGTH': 2},\n",
    "     {'TEXT': '-'},\n",
    "     {\"IS_DIGIT\": True, 'LENGTH': 2}],\n",
    "    [{'TEXT': '('},\n",
    "     {'TEXT': {'REGEX': r'\\d\\d\\d[)][-]\\d\\d\\d'}},\n",
    "     {'TEXT': '-'},\n",
    "     {\"IS_DIGIT\": True, 'LENGTH': 2},\n",
    "     {'TEXT': '-'},\n",
    "     {\"IS_DIGIT\": True, 'LENGTH': 2}],\n",
    "    [{'TEXT': '('},\n",
    "     {'TEXT': {'REGEX': r'\\d\\d[)][-]\\d'}},\n",
    "     {'TEXT': '-'},\n",
    "     {\"IS_DIGIT\": True, 'LENGTH': 2},\n",
    "     {'TEXT': '-'},\n",
    "     {\"IS_DIGIT\": True, 'LENGTH': 2}]\n",
    "]\n",
    "matcher = Matcher(py_nlp.vocab)\n",
    "matcher.add(\"PROPER_PHONE_NUMBER\", patterns)\n",
    "matches = matcher(doc)\n",
    "for match in matches:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Знаходження номерів телефонів*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Замінимо цифри на зірочки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At three  o'clock 12/05/1895 precisely I was at Baker Street, but Holmes had not\n",
      "yet returned (0**)-***-**-**. The landlady informed me that he baker_street@here.uk had left the house\n",
      "shortly after eight o'clock in the morning. I sat down beside the\n",
      "fire, however, with the intention of awaiting him,, however long he\n",
      "might be. 1******** I was already 6*-**-** deeply interested in his inquiry, for, though\n",
      "it was surrounded by none of the grim and strange features which\n",
      "were Watson3@gmail.com associated with the two crimes which I have already recorded,\n",
      "still, the nature of  the case and the exalted station of his client\n",
      "gave it a character of its own 1896/01/23.. Indeed, apart from the nature of the\n",
      "investigation which my friend had on hand, there was something in his\n",
      "masterly 5618 4582 8225 1471 grasp of a situation, and his (0*)-*-**-** keen, incisive reasoning, which\n",
      "made it a pleasure to me to study his system of work, and to follow the\n",
      "quick, subtle 4987 1514 6555 4212 methods by which he disentangled the most inextricable\n",
      "mysteries. So accustomed was I ShHolmes@mail.uk to his invariable success that the very\n",
      "possibility of his failing  had ceased to enter into my head.\n"
     ]
    }
   ],
   "source": [
    "tokens = [el.text for el in doc]\n",
    "for match in matches:\n",
    "    found_first_digit = False\n",
    "    elememts = []\n",
    "    tt = doc[match[1]:match[2]]\n",
    "    for i, el in enumerate(tt):\n",
    "        chars = list(el.text)\n",
    "        for j, c in enumerate(chars):\n",
    "            if c.isdigit() and not found_first_digit:\n",
    "                found_first_digit = True\n",
    "                continue\n",
    "            elif c.isdigit() and found_first_digit:\n",
    "                chars[j] = '*'\n",
    "        elememts.append(''.join(chars))\n",
    "    s = s.replace(tt.text, f''.join(elememts))\n",
    "print(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Заміна тексту*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Завдання друге"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зчитаємо файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'lab7-1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mlab7-1.txt\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m      2\u001b[0m     s \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(file\u001b[39m.\u001b[39mreadlines())\n\u001b[1;32m      3\u001b[0m doc \u001b[39m=\u001b[39m py_nlp(s)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lab7-1.txt'"
     ]
    }
   ],
   "source": [
    "with open('lab7-1.txt', 'r') as file:\n",
    "    s = ''.join(file.readlines())\n",
    "doc = py_nlp(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Зчитування файлів*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Знайдемо та виведемо стоп-слова, які присутні у тексті."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At',\n",
       " 'three',\n",
       " 'I',\n",
       " 'was',\n",
       " 'at',\n",
       " 'but',\n",
       " 'had',\n",
       " 'not',\n",
       " 'yet',\n",
       " 'The',\n",
       " 'me',\n",
       " 'that',\n",
       " 'he',\n",
       " 'had',\n",
       " 'the',\n",
       " 'after',\n",
       " 'eight',\n",
       " 'in',\n",
       " 'the',\n",
       " 'I',\n",
       " 'down',\n",
       " 'beside',\n",
       " 'the',\n",
       " 'however',\n",
       " 'with',\n",
       " 'the',\n",
       " 'of',\n",
       " 'him',\n",
       " 'however',\n",
       " 'he',\n",
       " 'might',\n",
       " 'be',\n",
       " 'I',\n",
       " 'was',\n",
       " 'already',\n",
       " 'in',\n",
       " 'his',\n",
       " 'for',\n",
       " 'though',\n",
       " 'it',\n",
       " 'was',\n",
       " 'by',\n",
       " 'none',\n",
       " 'of',\n",
       " 'the',\n",
       " 'and',\n",
       " 'which',\n",
       " 'were',\n",
       " 'with',\n",
       " 'the',\n",
       " 'two',\n",
       " 'which',\n",
       " 'I',\n",
       " 'have',\n",
       " 'already',\n",
       " 'still',\n",
       " 'the',\n",
       " 'of',\n",
       " 'the',\n",
       " 'and',\n",
       " 'the',\n",
       " 'of',\n",
       " 'his',\n",
       " 'it',\n",
       " 'a',\n",
       " 'of',\n",
       " 'its',\n",
       " 'own',\n",
       " 'Indeed',\n",
       " 'from',\n",
       " 'the',\n",
       " 'of',\n",
       " 'the',\n",
       " 'which',\n",
       " 'my',\n",
       " 'had',\n",
       " 'on',\n",
       " 'there',\n",
       " 'was',\n",
       " 'something',\n",
       " 'in',\n",
       " 'his',\n",
       " 'of',\n",
       " 'a',\n",
       " 'and',\n",
       " 'his',\n",
       " 'which',\n",
       " 'made',\n",
       " 'it',\n",
       " 'a',\n",
       " 'to',\n",
       " 'me',\n",
       " 'to',\n",
       " 'his',\n",
       " 'of',\n",
       " 'and',\n",
       " 'to',\n",
       " 'the',\n",
       " 'by',\n",
       " 'which',\n",
       " 'he',\n",
       " 'the',\n",
       " 'most',\n",
       " 'So',\n",
       " 'was',\n",
       " 'I',\n",
       " 'to',\n",
       " 'his',\n",
       " 'that',\n",
       " 'the',\n",
       " 'very',\n",
       " 'of',\n",
       " 'his',\n",
       " 'had',\n",
       " 'to',\n",
       " 'into',\n",
       " 'my']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = [token.text for token in doc if token.is_stop]\n",
    "stop_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Стоп-слова*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Знайдемо та виведемо всі іменники з тексту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[o'clock,\n",
       " landlady,\n",
       " house,\n",
       " o'clock,\n",
       " morning,\n",
       " fire,\n",
       " intention,\n",
       " inquiry,\n",
       " none,\n",
       " features,\n",
       " crimes,\n",
       " nature,\n",
       " case,\n",
       " station,\n",
       " client,\n",
       " character,\n",
       " 1896/01/23,\n",
       " nature,\n",
       " investigation,\n",
       " friend,\n",
       " hand,\n",
       " grasp,\n",
       " situation,\n",
       " reasoning,\n",
       " pleasure,\n",
       " system,\n",
       " work,\n",
       " methods,\n",
       " mysteries,\n",
       " success,\n",
       " possibility,\n",
       " failing,\n",
       " head]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = [token for token in doc if token.pos_ == 'NOUN']\n",
    "nouns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Іменники*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Виведемо числа та дати."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3884770101205390969, 1, 2) three\n",
      "(3884770101205390969, 22, 23) 34\n",
      "(3884770101205390969, 24, 25) 23\n",
      "(3884770101205390969, 40, 41) eight\n",
      "(3884770101205390969, 71, 72) 145\n",
      "(3884770101205390969, 72, 73) 124\n",
      "(3884770101205390969, 73, 74) 245\n",
      "(3884770101205390969, 77, 78) 67\n",
      "(3884770101205390969, 79, 80) 56\n",
      "(3884770101205390969, 81, 82) 34\n",
      "(3884770101205390969, 110, 111) two\n",
      "(3884770101205390969, 168, 169) 5618\n",
      "(3884770101205390969, 169, 170) 4582\n",
      "(3884770101205390969, 170, 171) 8225\n",
      "(3884770101205390969, 171, 172) 1471\n",
      "(3884770101205390969, 182, 183) 45\n",
      "(3884770101205390969, 184, 185) 34\n",
      "(3884770101205390969, 213, 214) 4987\n",
      "(3884770101205390969, 214, 215) 1514\n",
      "(3884770101205390969, 215, 216) 6555\n",
      "(3884770101205390969, 216, 217) 4212\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(py_nlp.vocab)\n",
    "patterns = [[{'LIKE_NUM': True}]]\n",
    "matcher.add(\"PROPER_PHONE_NUMBER\", patterns)\n",
    "matches = matcher(doc)\n",
    "for match in matches:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Числа та дати*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
